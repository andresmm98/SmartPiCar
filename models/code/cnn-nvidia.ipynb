{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB8TGLVtmiT5"
      },
      "source": [
        "# Deep learning model for a robotic autonomous car\n",
        "This is the main notebook of the project.\n",
        "The model is inspired by the architecture proposed in this paper from Nvidia: https://arxiv.org/pdf/1604.07316.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djlXs9jmpiE_"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "6y76l0jqlRM_",
        "outputId": "17ca502f-9596-4838-e4ed-9b58469143ad"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-000ca1b6ae67>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    127\u001b[0m   )\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "# Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXUxvUuhpjuj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import math\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# image handling\n",
        "from imgaug import augmenters as iaa\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# machine learning\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Conv2D, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print( f'tf.version: {tf.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q_OiKowQccv"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0JdbuifsGNR"
      },
      "source": [
        "### Image loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd2ITdBeFERx"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/My Drive/Mi educación/TFGs/TFG inf/driving-frames'\n",
        "model_output_dir = '/content/drive/My Drive/Mi educación/TFGs/TFG inf/trained-models'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94squGR2sJaN"
      },
      "outputs": [],
      "source": [
        "# Dataset creation\n",
        "# --------\n",
        "# The training set is composed by frames of the driving videos obatined by the\n",
        "# car camera. Each frame is an image whose name contains the steering angle in\n",
        "# which the car had to drive to follow the lane lines and keep itslef in the\n",
        "# circuit. Those angles where computed while driving the car manually with the\n",
        "# method manual_driver of SmartPiCar. The obtained images and its angles where\n",
        "# manually cleaned and corrected to account for some bad entries.\n",
        "#\n",
        "# The validation set is composed by frames of different driving videos,\n",
        "# including different circuits. This improved the performance of the model\n",
        "# significantly.\n",
        "#\n",
        "# For the labels, they come from the names of the images.\n",
        "#   - 90º: keep going straight\n",
        "#   - <90º: turn left\n",
        "#   - >90º: turn right\n",
        "\n",
        "def get_image_paths(directory, extension='png'):\n",
        "  \"\"\"Return an ordered list of all .png files in a given directory.\"\"\"\n",
        "  file_names = os.listdir(directory)\n",
        "  file_names = sorted(file_names)\n",
        "  img_paths = [os.path.join(directory,name) for name in file_names if name[-4:]\n",
        "               == f'.{extension}']\n",
        "\n",
        "  return img_paths\n",
        "\n",
        "train_img_paths = get_image_paths(os.path.join(data_dir,'training'))\n",
        "val_img_paths = get_image_paths(os.path.join(data_dir,'validation'))\n",
        "\n",
        "train_angles = [int(name[-7:-4]) for name in train_img_paths]\n",
        "val_angles = [int(name[-7:-4]) for name in val_img_paths]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5CoUfUOHL-r"
      },
      "source": [
        "### Data verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4M2fFvK-K5Qi"
      },
      "outputs": [],
      "source": [
        "# Training set\n",
        "\n",
        "# Check that the number of features and labels is the same\n",
        "print(f'Number of images for training: {len(train_img_paths)}')\n",
        "print(f'Number of steering angles: {len(train_angles)}')\n",
        "\n",
        "# Visualize four images and check that its steering angle is correct\n",
        "nrow, ncol = 2, 2\n",
        "fig, axes = plt.subplots(nrow, ncol, figsize=(9, 6))\n",
        "\n",
        "for ax in axes.flatten():\n",
        "  index = np.random.randint(0, len(train_img_paths) - 1)\n",
        "  ax.imshow(Image.open(train_img_paths[index]))\n",
        "  ax.set_title((f'Training image nº {index}\\n'\n",
        "                f'Steering angle: {train_angles[index]}º'))\n",
        "\n",
        "fig.tight_layout(pad=2.0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmP_Bf9jxFBT"
      },
      "outputs": [],
      "source": [
        "# Validation set\n",
        "\n",
        "# Check that the number of features and labels is the same\n",
        "print(f'Number of images for validation: {len(val_img_paths)}')\n",
        "print(f'Number of steering angles: {len(val_angles)}')\n",
        "\n",
        "# Visualize four images and check that its steering angle is correct\n",
        "nrow, ncol = 2, 2\n",
        "fig, axes = plt.subplots(nrow, ncol, figsize=(9, 6))\n",
        "\n",
        "for ax in axes.flatten():\n",
        "  index = np.random.randint(0, len(val_img_paths) - 1)\n",
        "  ax.imshow(Image.open(val_img_paths[index]))\n",
        "  ax.set_title((f'Validation image nº {index}\\n'\n",
        "                f'Steering angle: {val_angles[index]}º'))\n",
        "\n",
        "fig.tight_layout(pad=2.0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFBKsUTBI7yq"
      },
      "outputs": [],
      "source": [
        "# Check steering angle distribution for both sets\n",
        "fig, axes = plt.subplots(2,1, figsize=(12, 12))\n",
        "axes[0].hist(train_angles, bins=30, width=1, color='blue')\n",
        "axes[0].set_title('Training set')\n",
        "\n",
        "axes[1].hist(val_angles, bins=30, width=1, color='red')\n",
        "axes[1].set_title('Validation set')\n",
        "\n",
        "fig.supxlabel('Angle')\n",
        "fig.supylabel('Images')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoWDmEj3HDGE"
      },
      "source": [
        "### Volteado de las imágenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvT9B957qSSn"
      },
      "outputs": [],
      "source": [
        "imgs_have_been_flipped = True\n",
        "\n",
        "def flip_driving_frames(frame_paths, frame_angles, output_dir=False):\n",
        "  \"\"\"Flip a list of images horizontally and one of angles with respect to 90º.\n",
        "\n",
        "  The new images are stored with the new angle in their name at the same\n",
        "  directory.\n",
        "  \"\"\"\n",
        "  img_dir = frame_paths[0][:-23]\n",
        "\n",
        "  if not output_dir:\n",
        "    output_dir = img_dir\n",
        "\n",
        "  for i in range(len(frame_paths)):\n",
        "\n",
        "    img = cv2.imread(frame_paths[i])\n",
        "    img = cv2.flip(img,1)\n",
        "\n",
        "    # inversión del ángulo\n",
        "    img_angle = 180 - frame_angles[i]\n",
        "    img_angle = str(img_angle)\n",
        "    zero_angle = img_angle.zfill(3)\n",
        "\n",
        "    # se cambia el nombre con la nueva dirección\n",
        "    img_name = f'{frame_paths[i][-21:-9]}i-a{zero_angle}.png'\n",
        "    img_path = os.path.join(output_dir,img_name)\n",
        "\n",
        "    cv2.imwrite(img_path, img)\n",
        "\n",
        "  imgs_have_been_flipped = True\n",
        "\n",
        "# Flipped images are saved in memory, so the method has to execute\n",
        "# only once.\n",
        "if not imgs_have_been_flipped:\n",
        "  flip_driving_frames(train_img_paths, train_angles)\n",
        "  flip_driving_frames(val_img_paths, val_angles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBaNpi5iI0nQ"
      },
      "source": [
        "### Batch generator (discarded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCyFfdQz4RuM"
      },
      "outputs": [],
      "source": [
        "def flip_images(img_paths, steering_angles):\n",
        "  \"\"\"Flip the images horizontally and flip the angles around 90º.\"\"\"\n",
        "\n",
        "  aug_images = []\n",
        "  new_st_angles = []\n",
        "\n",
        "  for i in range(len(img_paths)):\n",
        "\n",
        "    image = cv2.imread(img_paths[i])\n",
        "    aug_images.append(image)\n",
        "    new_st_angles.append(steering_angles[i])\n",
        "\n",
        "    aug_images.append(cv2.flip(image,1))\n",
        "    new_st_angles.append(180 - steering_angles[i])\n",
        "\n",
        "  random.Random(870652).shuffle(aug_images)\n",
        "  random.Random(870652).shuffle(new_st_angles)\n",
        "\n",
        "  return aug_images, new_st_angles\n",
        "\n",
        "def flip(image, steering_angle):\n",
        "  flipped_image = cv2.flip(image,1)\n",
        "  steering_angle = 180 - steering_angle\n",
        "\n",
        "  return flipped_image, steering_angle\n",
        "\n",
        "def blur(image):\n",
        "  ksize = np.random.randint(1,5)\n",
        "  blurred_image = cv2.blur(image, (ksize,ksize))\n",
        "\n",
        "  return blurred_image\n",
        "\n",
        "def change_brightness(image):\n",
        "  brightness = iaa.Multiply((0.5, 1.2))\n",
        "  image = brightness.augment_image(image)\n",
        "\n",
        "  return image\n",
        "\n",
        "\n",
        "def img_augment(image, steering_angle):\n",
        "  \"\"\"Augments a random image\"\"\"\n",
        "  if np.random.rand() < 0.5:\n",
        "    image, steering_angle = flip(image, steering_angle)\n",
        "  if np.random.rand() < 0.5:\n",
        "    image = blur(image)\n",
        "  if np.random.rand() < 0.5:\n",
        "    image = change_brightness(image)\n",
        "\n",
        "  return image, steering_angle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTteZ8sVI4Eq"
      },
      "outputs": [],
      "source": [
        "def batch_generator(image_paths, steering_angles, batch_size):\n",
        "\n",
        "  batch_images = []\n",
        "  batch_steering_angles = []\n",
        "  seed = 123\n",
        "\n",
        "  for i in range(batch_size):\n",
        "    index = random.Random(i+seed).randint(0, len(image_paths) - 1)\n",
        "    img = cv2.imread(image_paths[index])\n",
        "\n",
        "    img_paths, steering_angle = img_augment(img, steering_angles[index])\n",
        "\n",
        "    img = img_preprocess(img)\n",
        "\n",
        "    batch_images.append(img)\n",
        "    batch_steering_angles.append(steering_angle)\n",
        "\n",
        "  yield(np.asarray(batch_images), np.asarray(batch_steering_angles))\n",
        "\n",
        "\"\"\"\n",
        "#test\n",
        "nrows = 2\n",
        "ncols = 2\n",
        "\n",
        "X_train_batch, y_train_batch = next(batch_generator(X_train, y_train, nrows))\n",
        "X_valid_batch, y_valid_batch = next(batch_generator(X_val, y_val, nrows))\n",
        "\n",
        "fig, axes = plt.subplots(nrows, ncols, figsize=(15, 6))\n",
        "#fig.tight_layout()\n",
        "\n",
        "for i in range(nrows):\n",
        "    axes[i][0].imshow(X_train_batch[i])\n",
        "    axes[i][0].set_title(\"training, angle=%s\" % y_train_batch[i])\n",
        "    axes[i][1].imshow(X_valid_batch[i])\n",
        "    axes[i][1].set_title(\"validation, angle=%s\" % y_valid_batch[i])\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJGta_JQKE7a"
      },
      "outputs": [],
      "source": [
        "class data_generator(tf.keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, x_set, y_set, batch_size, shuffle=True):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.x) / self.batch_size)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle == True:\n",
        "            np.random.Random(123).shuffle(self.x)\n",
        "            np.random.Random(123).shuffle(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[idx * self.batch_size:(idx + 1) *\n",
        "        self.batch_size]\n",
        "        batch_y = self.y[idx * self.batch_size:(idx + 1) *\n",
        "        self.batch_size]\n",
        "\n",
        "        images = []\n",
        "\n",
        "        for i in range(len(batch_x)):\n",
        "          img = cv2.imread(batch_x[i])\n",
        "\n",
        "          img, batch_y[i] = img_augment(img, batch_y[i])\n",
        "          img = img_preprocess(img)\n",
        "\n",
        "          images.append(img)\n",
        "\n",
        "        return np.array(images), np.array(batch_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlLKvnQtNsei"
      },
      "source": [
        "## Deep learning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8aOSPtX12PM"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "The model takes as an input an image of size 200x66 and returns a number.\n",
        "\n",
        "The input size is due to the fact that the car only needs the lower half of\n",
        "the image to guess the best steering angle.\n",
        "\n",
        "The output number is the estimated steering angle for that image.\n",
        "\"\"\"\n",
        "model = tf.keras.Sequential([\n",
        "\n",
        "  # augmenting layers, discarded because they didn't improve performance\n",
        "  # model.add(keras.layers.RandomContrast(0.1))\n",
        "  # model.add(keras.layers.RandomBrightness(0.1, value_range=(0, 1)))\n",
        "\n",
        "  # convolutional layers\n",
        "  Conv2D(24, 5, strides=(2, 2), input_shape=(66, 200, 3),\n",
        "                         activation='elu'),\n",
        "  Conv2D(36, 5, strides=(2, 2), activation='elu'),\n",
        "  Conv2D(48, 5, strides=(2, 2), activation='elu'),\n",
        "  Conv2D(64, 3, activation='elu'),\n",
        "  Conv2D(64, 3, activation='elu'),\n",
        "\n",
        "  # fully connected layers\n",
        "  keras.layers.Flatten(),\n",
        "\n",
        "  Dense(100, activation='elu'),\n",
        "  Dense(50, activation='elu'),\n",
        "  keras.layers.Dense(10, activation='elu'),\n",
        "\n",
        "  # output layer\n",
        "  Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EhhVqmqN0ye"
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "model.compile(loss='mse', optimizer=opt, metrics='MeanAbsoluteError')\n",
        "\n",
        "model.build((32,66,200,3))\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWLDrcGbSUNo"
      },
      "source": [
        "## Image preprocessing for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6x7P_Pwp5HH"
      },
      "outputs": [],
      "source": [
        "def img_preprocess(image_path):\n",
        "\n",
        "  img = cv2.imread(image_path)\n",
        "\n",
        "  # discard the upper part of the image\n",
        "  height = len(img)\n",
        "  img = img[int(height/2):,:,:]\n",
        "\n",
        "  img = cv2.resize(img, (200,66))\n",
        "\n",
        "  # change the color system. It was seen to improve performance\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  img = img / 255\n",
        "\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parallel_img_preprocess(image_paths):\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        images = list(executor.map(img_preprocess, image_paths))\n",
        "    return np.asarray(images)"
      ],
      "metadata": {
        "id": "V5_OjJthhcLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OX-hrrnuVty"
      },
      "outputs": [],
      "source": [
        "# apply preprocessing function to the datasets & convert to numpy\n",
        "# X_train = np.asarray([img_preprocess(i) for i in train_img_paths])\n",
        "# X_val = np.asarray([img_preprocess(i) for i in val_img_paths])\n",
        "\n",
        "X_train = parallel_img_preprocess(train_img_paths)\n",
        "X_val = parallel_img_preprocess(val_img_paths)\n",
        "\n",
        "Y_train = np.asarray(train_angles)\n",
        "Y_val = np.asarray(val_angles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aKLf0nyQUQQ"
      },
      "outputs": [],
      "source": [
        "# Check a sample of the dataset\n",
        "index = np.random.randint(0, len(val_angles) - 1)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
        "axes[0].imshow(Image.open(train_img_paths[index]))\n",
        "axes[0].set_title(f'Original image, angle: {train_angles[index]}º')\n",
        "axes[1].imshow(X_train[index])\n",
        "axes[1].set_title(f'Preprocessed image, angle: {Y_train[index]}º')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lr8tnirUvAM"
      },
      "outputs": [],
      "source": [
        "print(f'The shape of the training dataset is: {X_train.shape} '\n",
        "      f'& it has {len(Y_train)} labels.')\n",
        "print(f'The shape of the training dataset is: {X_val.shape} '\n",
        "      f'& it has {len(Y_val)} labels.\\n')\n",
        "\n",
        "# Visualize four images and check that its steering angle is correct\n",
        "nrow, ncol = 2, 2\n",
        "fig, axes = plt.subplots(nrow, ncol, figsize=(15, 6))\n",
        "\n",
        "for i in range(nrow):\n",
        "    axes[i][0].imshow(X_train[i])\n",
        "    axes[i][0].set_title(f'Training image. Angle: {Y_train[i]}º')\n",
        "    axes[i][1].imshow(X_val[i])\n",
        "    axes[i][1].set_title(f'Validation image. Angle: {Y_val[i]}º')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clear some variables to free up memory\n",
        "del(train_img_paths)\n",
        "del(val_img_paths)"
      ],
      "metadata": {
        "id": "yKHvoL88kbcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7yZH8nGFMQS"
      },
      "source": [
        "## Training and results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRRvUX4cUI8k"
      },
      "outputs": [],
      "source": [
        "history = None\n",
        "model_name = 'lane-nav'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q10ZkwytFVOC"
      },
      "outputs": [],
      "source": [
        "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=os.path.join(model_output_dir, f'{model_name}-checkpoint.h5'),\n",
        "                          verbose=1, save_best_only=True)\n",
        "\n",
        "history = model.fit(X_train, Y_train, batch_size=32,\n",
        "                              epochs=10,\n",
        "                              validation_data = (X_val, Y_val),\n",
        "                              verbose=1,\n",
        "                              shuffle=1,\n",
        "                              callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model with its mean absolute error on the validation set\n",
        "mean_absolute_error = round(model.metrics[1].result().numpy(),2)\n",
        "filename = f'{model_name}-{mean_absolute_error:.2f}.keras'\n",
        "model.save(os.path.join(model_output_dir, filename), save_format='keras')"
      ],
      "metadata": {
        "id": "GujmnuZVUM39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q212Xy8nkQV9"
      },
      "outputs": [],
      "source": [
        "# plot learning curves\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "ax = fig.add_subplot()\n",
        "\n",
        "ax.plot(train_loss, label='Training loss')\n",
        "ax.plot(val_loss, label='Validation loss')\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Mean cuadratic error')\n",
        "plt.title('Training nº 48')\n",
        "plt.xlabel('epoch', labelpad=2)\n",
        "\n",
        "ax.yaxis.tick_right()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZjAnGoIk0Ic"
      },
      "source": [
        "## Model re-training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfK3J_SWGfXu"
      },
      "outputs": [],
      "source": [
        "# After training the model, more data was collected. That motivated the\n",
        "# creation of these lines of code to continue training the model with this\n",
        "# data.\n",
        "\n",
        "# clear some variables to free up memory\n",
        "del(model)\n",
        "\n",
        "# load a trained model\n",
        "model_name = 'lane-nav'\n",
        "trained_model = keras.models.load_model(os.path.join(model_output_dir,\n",
        "                                                     f'{model_name}.keras'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icdNdhqyGhus"
      },
      "outputs": [],
      "source": [
        "# load more images\n",
        "ft_img_paths = get_image_paths(os.path.join(data_dir,'fine-tuning'))\n",
        "ft_angles = [int(name[-7:-4]) for name in ft_img_paths]\n",
        "\n",
        "# Images have already been flipped\n",
        "# flip_driving_frames(ft_img_paths, ft_angles)\n",
        "\n",
        "X_train_ft = np.asarray([img_preprocess(i) for i in ft_img_paths])\n",
        "Y_train_ft = np.asarray(ft_angles)\n",
        "X_train = np.concatenate((X_train, X_train_ft))\n",
        "Y_train = np.concatenate((Y_train, Y_train_ft))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgzFAmUEkzGE"
      },
      "outputs": [],
      "source": [
        "# new compilation and training\n",
        "trained_model.compile(loss='mse', optimizer=keras.optimizers.Adam(\n",
        "    learning_rate=0.00003)) # lower learning rate\n",
        "\n",
        "new_name = f'{model_name}-ft2'\n",
        "\n",
        "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=os.path.join(model_output_dir, f'{new_name}-checkpoint.h5'),\n",
        "    verbose=1, save_best_only=True)\n",
        "\n",
        "history_ft = trained_model.fit(X_train, Y_train, batch_size=32,\n",
        "                              epochs=5,\n",
        "                              validation_data = (X_val, Y_val),\n",
        "                              verbose=1,\n",
        "                              shuffle=1,\n",
        "                              callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model with its mean absolute error on the validation set\n",
        "mean_absolute_error = round(model.metrics[1].result().numpy(),2)\n",
        "filename = f'{new_name}-{mean_absolute_error:.2f}.keras'\n",
        "model.save(os.path.join(model_output_dir, filename), save_format='keras')"
      ],
      "metadata": {
        "id": "SAVClkOwcGWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q_WsbpLGm57"
      },
      "outputs": [],
      "source": [
        "# plot learning curves\n",
        "train_loss = history_ft.history['loss']\n",
        "val_loss = history_ft.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "\n",
        "plt.plot(range(2, len(train_loss) + 2), train_loss, label='Training loss')\n",
        "plt.plot(range(2, len(train_loss) + 2), val_loss, label='Validation loss')\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Mean cuadratic error')\n",
        "plt.title('Training nº 48')\n",
        "plt.xlabel('epoch', labelpad=2)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZWLDrcGbSUNo",
        "cLZHsXISP3q4"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyNtiDIOXCrUdAbd9pjEbTed"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}